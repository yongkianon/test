#SSH to root user

yum -y install bind-utils net-tools nmap ntp wget python

#Should use centos7
wget http://public-repo-1.hortonworks.com/HDP/centos6/2.x/updates/2.4.0.0/hdp.repo -O /etc/yum.repos.d/hdp.repo
yum -y install hadoop hadoop-hdfs hadoop-libhdfs hadoop-yarn hadoop-mapreduce hadoop-client openssl zookeeper-server

#Setup JAVA, Scala, Spark in /opt

cd /opt
tar -zxvf scala-2.11.8.tgz
tar -zxvf spark-1.6.1-bin-hadoop2.6.tgz
tar -zxvf server-jre-8u92-linux-x64.tar.gz

mv spark-1.6.1-bin-hadoop2.6  spark-1.6.1
ln -s spark-1.6.1/   spark
ln -s scala-2.11.8/  scala
ln -s jdk1.8.0_92/   jdk1.8.0

chown -R root:root /opt

alternatives --install /usr/bin/scala    scala    /opt/scala/bin/scala    2
alternatives --install /usr/bin/scalac   scalac   /opt/scala/bin/scalac   2
alternatives --install /usr/bin/scaladoc scaladoc /opt/scala/bin/scaladoc 2
alternatives --install /usr/bin/scalap   scalap   /opt/scala/bin/scalap   2


vi /etc/hosts
192.168.1.11  nn1 rm1 nm1 jn1 zk1
192.168.1.12  nn2 rm2 nm2 jn2 zk2
192.168.1.13      dn1 nm3 jn3 zk3
192.168.1.14      dn2 nm4 jn4 zk4
192.168.1.15      dn3 nm5 jn5 zk5
192.168.1.16      dn4 nm6 jn6 zk6



mkdir -p /data/jn
mkdir -p /data/nn
mkdir -p /data/snn
mkdir -p /data/dn
mkdir -p /data/zk
chown -R hadoop:hadoop /app /data /etc/hadoop /etc/zookeeper


vi /etc/security/limits.conf
#Goto end of the file
root - nofile 32768
root - nproc  65536
 *   - nofile 32768
 *   - nproc  65536







vi /etc/profile.d/hadoop.sh

export HADOOP_HOME=/usr/hdp/current/hadoop-client
export HADOOP_COMMON_HOME=$HADOOP_HOME

export   HADOOP_HDFS_HOME=/usr/hdp/current/hadoop-hdfs-client
export HADOOP_MAPRED_HOME=/usr/hdp/current/hadoop-mapreduce-client
export          YARN_HOME=/usr/hdp/current/hadoop-yarn-client

export HADOOP_CONF_DIR=/etc/hadoop/conf
export   YARN_CONF_DIR=/etc/hadoop/conf

export        LOG_DIR=/app/logs
export HADOOP_LOG_DIR=/app/logs

export ZOOKEEPER_HOME=/usr/hdp/current/zookeeper-server

export SCALA_HOME=/opt/scala
export SPARK_HOME=/opt/spark
export JAVA_HOME=/opt/jdk1.8.0
export PATH=$JAVA_HOME/bin:$SPARK_HOME/bin:$PATH



#NTP and Firewall
systemctl disable chrony.service
systemctl enable  ntpd.service
systemctl start   ntpd

systemctl disable firewalld.service
systemctl mask    firewalld
systemctl stop    firewalld


#SELinux
vi /etc/sysconfig/selinux
SELINUX=permissive

reboot








#SSH to hadoop

#setup password-less login
ssh-keygen -t rsa
# Press ENTER when (Enter file in which to save the key (/home/hadoop/.ssh/id_rsa):)
# Press ENTER when (Enter passphrase (empty for no passphrase):)
# Press ENTER when (Enter same passphrase again:)

cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys


vi /etc/zookeeper/conf/zoo.cfg
dataDir=/data/zk
server.1=zk1:2888:3888
server.2=zk2:2888:3888
server.3=zk3:2888:3888

[zk1] echo 1 > /data/zk/myid
[zk2] echo 2 > /data/zk/myid
[zk3] echo 3 > /data/zk/myid




### You need 3 nodes ready by now ###

Setup HDP HA Cluster
1. Start the JournalNode daemon in ALL nodes
$HADOOP_HOME/sbin/hadoop-daemon.sh start journalnode
/usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh start journalnode
/usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh stop  journalnode

2. Format ACTIVE NameNode (nn1), folder dfs.namenode.name.dir
/usr/bin/hdfs namenode -format

3. Start NameNode daemon in ACTIVE NameNode (nn1)
$HADOOP_HOME/sbin/hadoop-daemon.sh start namenode
$HADOOP_HOME/sbin/hadoop-daemon.sh stop  namenode

4. Copy the HDFS metadata from ACTIVE NameNode (nn1) to STANDBY NameNode (nn2)
   on the STANDBY NameNode (nn2) which is unformatted
/usr/bin/hdfs namenode -bootstrapStandby

5. Start NameNode daemon in STANDBY NameNode (nn2)
$HADOOP_HOME/sbin/hadoop-daemon.sh start namenode

6. Start ZooKeeper service in ALL nodes
/usr/hdp/current/zookeeper-server/bin/zkServer.sh start
/usr/hdp/current/zookeeper-server/bin/zkServer.sh stop
/usr/hdp/current/zookeeper-server/bin/zkServer.sh status

7. Start the DataNode daemon in ALL DataNode machines
$HADOOP_HOME/sbin/hadoop-daemon.sh start datanode

8. Format and then start ZooKeeper failover controller in ACTIVE and STANDBY NameNode
/usr/bin/hdfs zkfc -formatZK
$HADOOP_HOME/sbin/hadoop-daemon.sh start zkfc
$HADOOP_HOME/sbin/hadoop-daemon.sh stop  zkfc

9. Check status of each NameNode
/usr/bin/hdfs haadmin -getServiceState nn1
/usr/bin/hdfs haadmin -getServiceState nn2

## TESTING
/usr/bin/hdfs haadmin -transitionToStandby nn2
/usr/bin/hdfs haadmin -forcemanual         nn2
/usr/bin/hdfs haadmin -failover        nn1 nn2

/usr/bin/hdfs haadmin -transitionToActive  --forcemanual nn1
/usr/bin/hdfs haadmin -transitionToStandby --forcemanual nn2


### RM HA ###

1. Check status of each RM node
/usr/bin/yarn rmadmin -getServiceState rm1
/usr/bin/yarn rmadmin -getServiceState rm2

/usr/bin/yarn rmadmin -checkHealth         rm1
/usr/bin/yarn rmadmin -transitionToActive  --forcemanual rm1
/usr/bin/yarn rmadmin -transitionToStandby --forcemanual rm2


